services:
  backend:
    build: ./apps/backend
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL=llama3.1:8b-instruct-q4_0
    extra_hosts:
      - "host.docker.internal:host-gateway"
   
  frontend:
    build: ./apps/frontend
    ports:
      - "3000:3000"


#services:
#  backend:
#    build: ./apps/backend
#    ports:
#      - "8000:8000"
#    environment:
#      - PYTHONPATH=/app
#    volumes:
#      - ./apps/backend:/app
#    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
#    
#  frontend:
#    build: ./apps/frontend
#    ports:
#      - "3000:3000"
#    volumes:
#      - ./apps/frontend:/app
#      - /app/node_modules
#    environment:
#      - CHOKIDAR_USEPOLLING=true
#      
  # We'll add Ollama later
  # ollama:
  #   image: ollama/ollama:latest
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
      
# volumes:
#   ollama_data: